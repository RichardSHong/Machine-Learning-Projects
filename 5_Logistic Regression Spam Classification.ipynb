{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./spambase(1).data\"\n",
    "data = np.loadtxt(filename, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= data.shape\n",
    "X= data[:,:-1]\n",
    "Y= data[:, -1]\n",
    "X_train = X[:(round(2/3*a[0]))]\n",
    "X_test = X[(round(2/3*a[0])):]\n",
    "Y_train = Y[:(round(2/3*a[0]))]\n",
    "Y_test = Y[(round(2/3*a[0])):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "YTrain = np.reshape(Y_train, (-1,1))\n",
    "YTest = np.reshape(Y_test, (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the X_train\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0, ddof=1)\n",
    "std_X_train = (X_train-mean)/std\n",
    "\n",
    "#Standardize the X_test\n",
    "std_X_test =  (X_test-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding Bias on X_train_std\n",
    "X_train_std_bias = np.column_stack((np.ones(np.shape(std_X_train)[0]), std_X_train))\n",
    "XTrain = X_train_std_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding Bias on X_test_std\n",
    "X_test_std_bias = np.column_stack((np.ones(np.shape(std_X_test)[0]), std_X_test))\n",
    "XTest= X_test_std_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.random.rand(58,1)*2-1\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(theta, X):\n",
    "    return 1 / (1 + np.exp(-(np.dot(X, theta))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegression_Spam(theta, learning_rate):\n",
    "    iterations = 1500\n",
    "    loss= 0\n",
    "    old_loss = 5000\n",
    "    for iteration in range(iterations):\n",
    "\n",
    "        gradients = probability(theta, XTrain)\n",
    "        theta = theta - (learning_rate/(np.shape(XTrain)[0])) * np.dot(XTrain.T,(gradients-YTrain))\n",
    "        loss = np.dot(-Y_train,(np.log(probability(theta, XTrain))))-np.dot((1-Y_train),np.log(1-probability(theta, XTrain)))\n",
    "        \n",
    "        \n",
    "        if abs(old_loss - loss) < 2**-23 :\n",
    "            break\n",
    "        old_loss = loss\n",
    "\n",
    "        \n",
    "        \n",
    "    Y_predict = probability(theta, XTest)\n",
    "    Y_test_smaple = (Y_predict > 0.5)*1\n",
    "    Y_test_Y_sample = np.hstack((YTest, Y_test_smaple))\n",
    "    \n",
    "\n",
    "    TP=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    TN=0\n",
    "    for a,b in Y_test_Y_sample:\n",
    "        if a==0 and b==0:\n",
    "            TP+=1\n",
    "        elif a==0 and b==1:\n",
    "            FN+=1\n",
    "        elif a==1 and b==0:\n",
    "            FP+=1\n",
    "        else:\n",
    "            TN+=1\n",
    "    print(\"TP: \", TP)\n",
    "    print(\"FP: \", FP)\n",
    "    print(\"FN: \", FN)\n",
    "    print(\"TN: \", TN)\n",
    "    \n",
    "    Accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "    Precision = TP/(TP+FP)\n",
    "    Recall = TP/(TP+FN)\n",
    "    F_measure = (2*Precision*Recall)/(Precision+Recall)\n",
    "    \n",
    "    print(\"Precision: \", Precision)\n",
    "    print(\"Recall: \", Recall)\n",
    "    print(\"F_measure: \", F_measure)\n",
    "    print(\"Accuracy: \", Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  866\n",
      "FP:  88\n",
      "FN:  92\n",
      "TN:  488\n",
      "Precision:  0.9077568134171907\n",
      "Recall:  0.9039665970772442\n",
      "F_measure:  0.905857740585774\n",
      "Accuracy:  0.8826597131681877\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression_Spam(theta, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9315514993481095"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Spam_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "Spam_model.fit(X_train, Y_train)\n",
    "pred = Spam_model.predict(X_test)\n",
    "accuracy_score(Y_test,pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
